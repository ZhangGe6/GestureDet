{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import torch\n",
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PLTPoltter():\n",
    "    def __init__(self, ax_size, **kwargs):\n",
    "        self.fig, self.ax = plt.subplots(*ax_size, **kwargs)\n",
    "\n",
    "    def plt_show_cv2_img(self, cv2_img, ax_id):\n",
    "        self.ax[ax_id].imshow(cv2_img[:, :, ::-1])\n",
    "\n",
    "    def plt_show_np_single_channel(self, np_array, channel, ax_id):\n",
    "        array = np_array[channel]\n",
    "        self.ax[ax_id].imshow(array)\n",
    "\n",
    "    def plt_show_np_concat(self, np_array, concat_num, ax_id):\n",
    "        channel, height, wdith = np_array.shape\n",
    "        concat = np.zeros((height, wdith))\n",
    "        for c in range(concat_num):\n",
    "            # print(np.max(np_array[c]))\n",
    "            concat += np_array[c]\n",
    "        self.ax[ax_id].imshow(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import UltraLightSimplePoseNet\n",
    "\n",
    "weight_path = './checkpoints/mobilenetv2_epoch_7_acc1_0.84.pt'\n",
    "model = UltraLightSimplePoseNet().cuda()\n",
    "model.load_state_dict(torch.load(weight_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import HandPoseDataset\n",
    "\n",
    "model_input_size = (256, 192)\n",
    "mdoel_output_size = (64, 48)\n",
    "\n",
    "data_root = '/home/zg/wdir/zg/moyu/GestureDet/datasets/MHP_dataset'\n",
    "hand_pose_dataset = HandPoseDataset(data_root=data_root, model_input_size=model_input_size, model_output_size=mdoel_output_size, split='test', debug_vis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch data\n",
    "sample_id = 80\n",
    "full_img_path = hand_pose_dataset.jpg_path_set[sample_id]\n",
    "full_img = cv2.imread(full_img_path)\n",
    "affined_img, target_mask, target_weight, affined_joints, bbox, joints = hand_pose_dataset.__getitem__(sample_id)\n",
    "\n",
    "full_img_gt = copy.deepcopy(full_img)\n",
    "xmin, ymin, xmax, ymax = bbox\n",
    "full_img_gt = cv2.rectangle(full_img_gt, (xmin, ymin), (xmax, ymax), color=(0, 0, 255), thickness=2)\n",
    "for pt in joints:\n",
    "    x, y = pt\n",
    "    full_img_gt = cv2.circle(full_img_gt, (x, y), radius=1, color=(0, 0, 255), thickness=5)\n",
    "\n",
    "affined_img_gt = copy.deepcopy(affined_img)\n",
    "for i, pt in enumerate(affined_joints):\n",
    "    x, y = pt\n",
    "    affined_img_gt = cv2.circle(affined_img_gt, (int(x), int(y)), radius=1, color=(0, 0, 255), thickness=2)\n",
    "    # cv2.putText(affined_img_gt, str(i),(int(x),int(y)),cv2.FONT_HERSHEY_COMPLEX,0.5,(0,0,255),1)\n",
    "# from pose_utils.vis import draw_joint_pair\n",
    "# affined_img_gt = draw_joint_pair(affined_img_gt, affined_joints)\n",
    "\n",
    "from pose_utils.vis import draw_result_from_heatmap\n",
    "joint_from_heatmap_img = draw_result_from_heatmap(affined_img, target_mask, feat_stride=4)\n",
    "\n",
    "plt_poltter = PLTPoltter(ax_size=(1, 5), figsize=(20, 10))\n",
    "plt_poltter.plt_show_cv2_img(full_img_gt, 0)   \n",
    "plt_poltter.plt_show_cv2_img(affined_img, 1) \n",
    "plt_poltter.plt_show_cv2_img(affined_img_gt, 2) \n",
    "plt_poltter.plt_show_np_concat(target_mask, 21, 3)\n",
    "plt_poltter.plt_show_cv2_img(joint_from_heatmap_img, 4)\n",
    "\n",
    "\n",
    "# see_channel = 5\n",
    "# plt_poltter.plt_show_np_single_channel(pred_mask_numpy, channel=see_channel, ax_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import UltraLightSimplePoseNet\n",
    "from pose_utils.transforms import to_tensor, norm\n",
    "\n",
    "norm_tensor_img = norm(to_tensor(affined_img), (-0.406, -0.457, -0.480))\n",
    "unsqueeze_norm_tensor_img = norm_tensor_img.unsqueeze(0).cuda()\n",
    "out_mask = model(unsqueeze_norm_tensor_img)\n",
    "pred_mask_numpy = out_mask[0].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pose_utils.vis import draw_result_from_heatmap\n",
    "affined_img_pred = copy.deepcopy(affined_img)\n",
    "joint_from_heatmap_img = draw_result_from_heatmap(affined_img_pred, pred_mask_numpy, feat_stride=4)\n",
    "\n",
    "# see mask\n",
    "plt_poltter = PLTPoltter(ax_size=(1, 2), figsize=(20, 10))\n",
    "plt_poltter.plt_show_cv2_img(affined_img, 0) \n",
    "plt_poltter.plt_show_cv2_img(joint_from_heatmap_img, 1)   \n",
    "see_channel = 20\n",
    "# plt_poltter.plt_show_np_single_channel(target_mask, see_channel, 1)\n",
    "# plt_poltter.plt_show_np_single_channel(pred_mask_numpy, see_channel, 2)\n",
    "# plt_poltter.plt_show_np_concat(target_mask, 21, 1)\n",
    "# plt_poltter.plt_show_np_concat(pred_mask_numpy, 21, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see joints\n",
    "from pose_utils.transforms import heatmap_to_coord_simple\n",
    "\n",
    "preds, maxvals = heatmap_to_coord_simple(pred_mask_numpy, bbox)\n",
    "pred_recover_joint_img = copy.deepcopy(full_img)\n",
    "for pt in preds:\n",
    "    x, y = pt\n",
    "    pred_recover_joint_img = cv2.circle(pred_recover_joint_img, center=(int(x), int(y)), radius=2, color=(255, 255, 255), thickness=2)\n",
    "\n",
    "gt_joints, maxvals = heatmap_to_coord_simple(target_mask, bbox)\n",
    "gt_recover_joint_img = copy.deepcopy(full_img)\n",
    "for pt in gt_joints:\n",
    "    x, y = pt\n",
    "    gt_recover_joint_img = cv2.circle(gt_recover_joint_img, center=(int(x), int(y)), radius=2, color=(255, 255, 255), thickness=2)\n",
    "\n",
    "plt_poltter = PLTPoltter(ax_size=(1, 2), figsize=(20, 10))\n",
    "plt_poltter.plt_show_cv2_img(pred_recover_joint_img, 0)   \n",
    "plt_poltter.plt_show_cv2_img(gt_recover_joint_img, 1) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e0647ecf0dfce2c803e6d23827cf1b72549446a90a5c8f13f4fbc3972468ba5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('mc': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
